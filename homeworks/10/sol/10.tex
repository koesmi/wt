\documentclass{article}
\usepackage[a4paper,margin=1.875in,top=1.5in,bottom=1.5in]{geometry}

\usepackage{amsmath,mathtools,bbm,amssymb}
\usepackage[german]{babel}

\usepackage{setspace}
\doublespacing

\usepackage{fancyhdr}
\renewcommand{\headrulewidth}{0pt} 
\pagestyle{fancy}
\lhead{Blatt 10 Nicolas und Evgenij}\rhead{Seite \thepage}
\fancyfoot{}

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,arrows}

\usepackage[numbers]{natbib}
\bibliographystyle{alphadin}
\usepackage{url}
\usepackage{hyperref}

\begin{document}

\paragraph{Aufgabe 1 \textnormal{(4 Punkte)}.}
Seien $Y$ und $Y_n$ für alle $n\in\mathbb{N}$ Zufallsvariablen mit Werten in $\mathbb{Z}$.
Zeigen Sie
\[
Y_n\Rightarrow Y\quad\Longleftrightarrow\quad\forall j\in\mathbb{Z}\colon P(Y_n=j)\xrightarrow{n\to\infty}P(Y=j).
\]
Wir verwenden die Rücktransformation der charakteristischen Funktionen $\varphi_n$ und $\varphi$ von $Y_n$ und $Y$.
Für $\varphi$ gilt
\[
  P(X=j)=\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}tj}\varphi(t)\mathrm{d}t\,.
\]
In der Tat gilt mit der Definition der charakteristischen Funktion
\begin{align*}
  \frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}tj}\varphi(t)\mathrm{d}t
  &=\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}jt}E_k\bigl[\mathrm{e}^{\mathrm{i}kt}\bigr]\mathrm{d}t\,.
    \intertext{Da $E_k$ nur Masse bei $X=k$ hat erhalten wir}
  &=\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}jt}\sum_{k\in\mathbb{Z}}\mathrm{e}^{\mathrm{i}kt}P(X=k)\mathrm{d}t
    \intertext{Zusammenfassen liefert das}
  &=\sum_{k\in\mathbb{Z}}P(X=k)\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{\mathrm{i}(k-j)t}\mathrm{d}t\,,
\end{align*}
\emph{wobei man sich eventuell überlegen sollte, ob man die Summe und das Integral vertauschen darf}. Wenn $k-j=0$, so ist der Integrand 1.
Wenn $k-j=\ell\neq0$, gilt
\begin{align*}
  \int_{-\pi}^\pi\mathrm{e}^{\mathrm{i}\ell t}\mathrm{d}t
  &=\frac{1}{\mathrm{i}\ell}\bigl(\mathrm{e}^{\mathrm{i}\ell\pi}-\mathrm{e}^{-\mathrm{i}\ell\pi}\bigr)=\frac{1}{\mathrm{i}\ell}\bigl((\pm1)-(\pm1)\bigr)=0\,.
\end{align*}
Eingesetzt in die obige Rechnung verschwinden somit alle Summanden mit $k\neq j$ und wir erhalten die Darstellung für die Rücktransformation der charakteristischen Funktion.
Entsprechendes gilt dann auch für $Y_n$ und $\varphi_n$.
Mithilfe dieser Rücktransformationen erhalten wir die gesuchte Konvergenz.
Für den Abstand von $P(Y_n=j)$ und $P(Y=j)$ gilt mithilfe Rücktransformation
\begin{align*}
  |P(Y_n=j)-P(Y=j)|
  &=\left|\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}tj}\varphi_n\mathrm{d}t-\frac{1}{2\pi}\int_{-\pi}^\pi\mathrm{e}^{-\mathrm{i}tj}\varphi\mathrm{d}t\right|\,.
    \intertext{Mit Zusammenfassen und der \glqq Dreiecksungleichung\grqq{} des Integrals können wir abschätzen}
  &\leq\frac{1}{2\pi}\int_{-\pi}^\pi\bigl|\mathrm{e}^{\mathrm{i}tj}\bigl(\varphi_n(t)-\varphi(t)\bigr)\bigr|\mathrm{d}t\,.
    \intertext{Das vereinfacht sich, weil $\bigl|\mathrm{e}^{\mathrm{i}tj}\bigr|=1$.
    Weiterhin konvergiert $\varphi_n(t)$ gegen $\varphi(t)$ nach dem Portmanteau-Theorem, denn $\mathrm{e}^{\mathrm{i}tj}$ ist Lipschitz-stetig.
    Da $|\varphi_n(t)|\leq1$ können wir schließlich den Satz über majorisierte Konvergenz verwenden und erhalten}
  &\xrightarrow{n\to\infty}0\,.
\end{align*}

Wenn andererseits für alle $j\in\mathbb{Z}$ gilt, dass $P(Y_n=j)\xrightarrow{n\to\infty}P(Y=j)$, dann gilt auch $\sum_{j\in\mathbb{Z}}f(j)P(Y_n=j)\xrightarrow{n\to\infty}\sum_{j\in\mathbb{Z}}f(j)P(Y=j)$ für alle $f\in{\cal C}_\mathrm{b}$ und somit $Y_n\Rightarrow Y$.
\newpage

\paragraph{Aufgabe 3 \textnormal{(4 Punkte)}.} Sei $(\alpha_n)_{n\in\mathbb{N}}$ eine Folge mit $\alpha_n\in(0,\infty)$.
Weiter sei $(X_n)_{n\in\mathbb{N}}$ eine Folge von Zufallsvariablen, sodass $X_n$ exponentialverteilt mit Parameter $\alpha_n$ ist, das heißt, $X_n$ besitzt die Dichte
\[
  f_n(x)=\mathbbm{1}_{\{x\geq0\}}\alpha_n\mathrm{e}^{-\alpha_n x}\,.
\]
Zeigen Sie die schwache Konvergenz von $(X_n)_{n\in\mathbb{N}}$ für $n\to\infty$, falls $\alpha_n\to\infty$ für $n\to\infty$.

Wir wollen den Satz von Lévy verwenden.
Demnach konvergiert $X_n$ in Verteilung gegen eine Zufallsvariable $X$, wenn $\varphi_n\xrightarrow{n\to\infty}\varphi$.
Es gilt $\varphi_n(t)=\frac{\alpha_n}{\alpha_n-\mathrm{i}t}$ und mit dem Satz von de L'Hospital $\lim_{n\to\infty}\frac{\alpha_n}{\alpha_n-\mathrm{i}t}=1$.
Da 1 stetig in 0 ist, konvergiert also auch $(X_n)$.
\newpage

\paragraph{Aufgabe 4 \textnormal{(4 Punkte)}.}
Zeigen Sie, dass es einen Homöomorphismus zwischen $\mathbb{R}$ und den Dirac Maßen auf $\mathbb{R}$ mit der schwachen Konvergenz gibt.

Wir nehmen an, dass der Homöomorphismus $x\mapsto\delta_x$ ist.
Da $x$ der einzige Parameter von $\delta_x$ ist, ist dieser schon mal bijektiv.

Wir zeigen noch, dass $x\mapsto\delta_x$ und $\delta_x\mapsto x$ stetig sind, also, dass Bilder und Urbilder offener Mengen offen sind.
In Bemerkung 13.14.iii in \cite{klenke} steht, dass die Prohorov-Metrik $d_\mathrm{P}$ eine Topologie auf dem Raum der endlichen Maße induziert.
Wir zeigen Stetigkeit bezüglich dieser Topologie.
Sei $d'_\mathrm{P}(\mu,\nu):=\inf\{\varepsilon>0:\mu(B)\leq\nu(B_\varepsilon)+\varepsilon\text{ für jedes }B\in{\cal B}(\mathbb{R})\}$, wobei $B_\varepsilon$ die offene $\varepsilon$-Umgebung um $B$ ist.
Dann ist $d_\mathrm{P}(\mu,\nu):=\max\{d'_\mathrm{P}(\mu,\nu),d'_\mathrm{P}(\nu,\mu)\}$.
In unserem Fall haben wir $\mu=\delta_x$ und $\nu=\delta_y$ für $x,y\in\mathbb{R}$.
Da die Situation symmetrisch in $x$ und $y$ ist, ist $d'_\mathrm{P}(\delta_x,\delta_y)=d'_\mathrm{P}(\delta_y,\delta_x)$ und es reicht $d_\mathrm{P}(\delta_x,\delta_y)=\mathrm{d}'_\mathrm{P}(\delta_x,\delta_y)$ anzuschauen.
Seien $x,y\in\mathbb{R}$ also gegeben.
Es gilt
\[
\delta_x(B)=
\begin{cases}
  1,&x\in B\,,\\
  0,&x\notin B
\end{cases}
\quad\text{und entsprechend }
\delta_y(B_\varepsilon)+\varepsilon=
\begin{cases}
  1+\varepsilon,&y\in B_\varepsilon\,,\\
  0,&y\notin B_\varepsilon\,.
\end{cases}
\]
Nach der Definition der Prohorov-Metrik suchen wir das Infimum von den $\varepsilon>0$, sodass für jedes $B\in {\cal B}(\mathbb{R})$ gilt $\delta_x(B)\leq\delta_y(B_\varepsilon)+\varepsilon$.
Falls $x\notin B$, ist diese Bedingung für alle $\varepsilon$ erfüllt, da $\delta_y>0$ und $\varepsilon>0$.
Falls $x\in B$ und $y\in B_\varepsilon$, ist die Bedingung ebenfalls trivial erfüllt, denn $\varepsilon>0$.
Falls $x\in B$ und $y\notin B_\varepsilon$, haben wir einen Fall, wie unten dargestellt
\begin{center}
  \begin{tikzpicture}
    \draw[-|](-3,0)--(-2.5,0)node[below]{$y$};
    \draw[-|](-2.5,0)--(-0,0)node[below]{$x$};
    \draw[->](0,0)--(3,0);
    \draw[{[-]}](-1,.5)to node[fill=white,midway]{$B$}(1,.5);
    \draw[{(-)}](-2,1)to node[fill=white,midway]{$B_\varepsilon$}(2,1);
    \draw[|-|](-2,1.5)to node[fill=white,midway]{$\varepsilon$}(-1,1.5);
\end{tikzpicture}
\end{center}
Wie ersichtlich ist $\varepsilon$ dann am größten, wenn $B=\{x\}$, es reicht uns also das Infimum der $\varepsilon$ für den Fall $B=\{x\}$ zu finden.
Dieses $\varepsilon$ wird die Ungleichung auch für alle anderen $B$ erfüllen.
Im Falle $B=\{x\}$ ist $B_\epsilon=B_\epsilon(x)$ und $y\notin B_\epsilon$ entspricht $|x-y|\geq\varepsilon$.
Somit ist die Ungleichung $\delta_x(B)\leq\delta_y(B_\varepsilon)+\varepsilon$ genau dann erfüllt, wenn entweder $\varepsilon\leq|x-y|$ oder $\varepsilon\geq1$.
Damit ist $d_\mathrm{P}(\delta_x,\delta_y)=|x-y|\wedge1$.

Sei $U\subset\mathbb{R}$ offen.
Sei $\delta_x$ in $\delta_U$ gegeben.
Sei $\varepsilon>0$ so, dass $B_\varepsilon(x)\subset U$.
Dann gilt für ein $\delta_y\in \delta_U$, dass $|x-y|<\varepsilon$, also auch $d_\mathrm{P}(\delta_x,\delta_y)=|x-y|\wedge1<\varepsilon$.
Somit ist $\delta_U$ offen.
Sei nun andererseits $\delta_U$ offen.
Sei $x\in U$ gegeben.
Sei $0<\varepsilon<1$ so, dass $B_\varepsilon\bigl(\delta(x)\bigr)\subset \delta_U$.
Dann gilt für ein $y\in U$, dass $d_\mathrm{P}(x,y)=|x-y|\wedge1<\varepsilon$, also auch, dass $|x-y|<\varepsilon$, denn, $\varepsilon<1$.
Das heißt, $B_\varepsilon(x)\subset U$, also ist $U$ offen.

Damit ist $x\mapsto\delta_x$ stetig bezüglich der durch die Prohorov-Metrik induzierten Topologie.
Insgesamt ist $x\mapsto \delta_x$ ein Homöomorphismus.

\emph{In Bemerkung 13.14.ii in \cite{klenke} steht allerdings auch, dass man auf den endlichen Maßen die gröbste Topologie, bezüglich welcher $\mu\mapsto\int f\mathrm{d}\mu$ stetig ist wählen kann.
Eventuell kann man das auch benutzen, um die Stetigkeit einfacher zu sehen.}

\bibliography{../../../books/wt}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% ispell-local-dictionary: "german"
%%% TeX-master: t
%%% End:
