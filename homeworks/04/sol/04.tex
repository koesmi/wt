\documentclass{article}
\usepackage[a4paper,margin=1.875in,top=1.1in,bottom=1.1in]{geometry}

\usepackage{amsmath,mathtools,bbm,amssymb}
\usepackage[german]{babel}

\usepackage{setspace}
\doublespacing

\usepackage{fancyhdr}
\renewcommand{\headrulewidth}{0pt} 
\pagestyle{fancy}
\lhead{Blatt 4 Nicolas und Evgenij}\rhead{Seite \thepage}
\fancyfoot{}

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing,arrows.meta}

\usepackage[numbers,round]{natbib}
\bibliographystyle{alphadin}
\usepackage{url}
\usepackage{hyperref}

\begin{document}

\paragraph{Satz 6} Hier haben wir verschiedene Ungleichungen Für Wahrscheinlichkeiten, Erwartungswerte und ${\cal L}^p$-Normen zu Verfügung.
Seien $X$, $Y$ reellwertige Zufallsvariable.
Dann gilt folgendes.
\begin{description}
\item[\emph{(i)}] Die \emph{Markov-Ungleichung} -- Sei $f\colon[0,\infty)\to[0,\infty)$ monoton wachsend, $\varepsilon>0$ so, dass $f(\varepsilon)>0$.
  Dann gilt
  \[P(|X|\geq\varepsilon)\leq\frac{E[f(X)]}{f(\varepsilon)}\,.\]
\item[\emph{(ii)}] Die \emph{Tschebyscheff-Ungleichung} -- ist $E[X^2]<\infty$, so gilt
  \[P(|X-E[X]|)>\varepsilon)\leq\frac{\operatorname{Var}(X)}{\varepsilon^2}\,.\]
\item[\emph{(iii)}] Die \emph{Hölder-Ungleichung} -- Für $0<p,q,r\leq\infty$ so, dass $\frac{1}{p}+\frac{1}{q}=\frac{1}{r}$ gilt
  \[\|XY\|_r\leq\|X\|_p\|Y\|_q\,.\]
\item[\emph{(iv)}] Die \emph{Minkowski-Ungleichung} -- für $1\leq p\leq\infty$ gilt
  \[\|X+Y\|_p\leq\|X\|_p+\|Y\|_p\,.\]
\item[\emph{(v)}] Das Analogon der Minkowski-Ungleichung im konkaven Fall -- für $0<p<1$ gilt
  \[E[|X+Y|^p]\leq E[|X|^p]+E[|Y|^p]\,.\]
\item[\emph{(vi)}] Eine Abschätzung Normen veschrschiedener ${\cal L}^p$-Räume. Für $p\leq q$ und $X\in{\cal L}^q$ gilt
  \[\|X\|_p\leq\|X\|_q\,.\]
\end{description}
\paragraph{Satz 8} Die \emph{Jensen-Ungleichung} -- sei $g\colon\mathbb{R}\to\mathbb{R}$ konvex und $X\in{\cal L}^1$, dann gilt
\[E[g(X)]\geq g(E[X])\,.\]

\paragraph{B4A1.1}
Haben $X_1(\omega)=\omega$ und $X_2(\omega)=1-\omega$ die gleiche Verteilung auf $([0,1],{\cal B}([0,1]),\lambda|_{[0,1]})$?
Ja.
Die Zufallsvariablen $X_1$ und $X_2$ auf $[0,1]$ sehen wie in der folgenden Skizze aus.
\begin{center}
  \begin{tikzpicture}
    \draw[-Bar](0,0)to node[midway,below]{$\Omega$}(1,0)node[below]{1};
    \draw[-Bar](0,-.5)--(0,1)node[left]{1};
    \draw[->](0,1)--(0,1.5)node[left]{$X_i$};
    \draw[thick](0,0)--(1,1)node[right]{$X_1$};
    \draw[thick](0,1)--(1,0)node[right]{$X_2$};
  \end{tikzpicture}
\end{center}
Es reicht, die Verteilung auf $\{[a,b]\}_{a,b\in\mathbb{Q}}$ zu betrachten.
Wegen dem Eindeutigkeitssatz A.16 wird die Verteilung auf ganz ${\cal B}([0,1])$ gleich sein.
Die Verteilung von $X_1$ ist $P_\#X_1=P\circ X_1^{-1}$.
Aus der Skizze erkennt man, $X_1^{-1}([a,b])=[a,b]$, sodass $P_\#X_1([a,b])=\lambda|_{[0,1]}([a,b])=b-a$.
Da auch $X_2$ monoton ist, können wir $X_2^{-1}([a,b])$ ebenfalls durch die Urbilder des Grenzen $a$ und $b$ von $[a,b]$ angeben.
Da $X_2$ fallend ist, müssen wir lediglich die Grenzen umdrehen, also $X_2^{-1}([a,b])=[X_2^{-1}(b),X_2^{-1}(a)]=[1-b,1-a]$ und $P_\#X_2([a,b])=\lambda|_{[0,1]}([1-b,1-a])=1-a-1+b=b-a=P_\#X_1([a,b])$.
\paragraph{B4A1.2}
Gibt es ein Wahrscheinlichkeitsmaß $P$ auf $([0,1],{\cal B}([0,1]))$, sodass $X_1(\omega)=\omega$ und $X_2(\omega)=1-\omega$ nicht die gleiche Verteilung haben? \emph{Siehe handschriftliches Blatt.}
\paragraph{B4A1.3}
Wenn $X\sim{\cal N}(2,2)$ verteilt ist, gilt $P[|X-2|\geq2]\leq\frac{1}{2}$?
Ja.
Nach der Tschebyscheff-Ungleichung gilt $P[|X-2|\geq2]\leq\frac{2}{2^2}=\frac{1}{2}$.
\paragraph{B4A1.4}
Jede reellwertige Zufallsvariable, also $X\colon \Omega\to\mathbb{R}$ messbar hat eine Dichte bezüglich $\lambda$?
Nein.
Sei $X=0$.
Dann ist $X$ stetig und somit messbar mit $P(X=0)=1$, also $P=\delta_0$.
Da $0=\lambda(\{0\})\neq\delta_0(\{0\})=1$, ist $\delta_0$ nicht absolut stetig bezüglich $\lambda$.
Nach dem Satz von Radon-Nikodym, so wie er als Korollar 7.34 in \cite{klenke} steht, besitzt dann $\delta_0$ keine Dichte bezüglich des Lebesgue-Maßes.
\paragraph{B4A1.5}
Auf $(\Omega,{\cal P}(\Omega))$ sind alle Abbildungen $(\Omega,{\cal P}(\Omega))\to(\mathbb{R},{\cal B}(\mathbb{R}))$ messbar?
Ja.
Sei $A\in{\cal B}(\mathbb{R})$, dann ist $f^{-1}(A)\in{\cal P}(\Omega)$, denn in ${\cal P}(\Omega)$ sind alle Mengen, die nach $A$ abbilden könnten, drin.
\paragraph{B4A1.6}
Für $X\sim{\cal N}(0,1)$ und $Y\sim{\cal N}(0,2)$ gilt $E[XY]\leq\sqrt{2}$?
Ja, denn nach der Cauchy--Schwarz-Ungleichung, also der Hölder-Ungleichung mit $r=1$ und $p=q=2$ gilt
\begin{align*}
E[XY]
  &\leq\|X\|_2\|Y\|_2\,.
    \intertext{Mit der Definition der ${\cal L}^p$-Norm und weil Quadrate positiv sind haben wir}
  &=\sqrt{E[X^2]}\sqrt{E[Y^2]}\,.
    \intertext{Die Angabe $X\sim{\cal N}(0,1)$ heißt $E[X]=E[Y]=0$ und wir können schreiben}
  &=\sqrt{E[(X-E[X])^2]}\sqrt{E[(Y-E[Y])^2]}\,.
    \intertext{Mit der Definition der Varianz ergibt sich}
  &=\sqrt{\operatorname{Var}(X)}\sqrt{\operatorname{Var}(Y)}\,.
    \intertext{Die Angabe $X\sim{\cal N}(0,1)$ heißt, $\operatorname{Var}(X)=1$ und $\operatorname{Var}(Y)=2$.
    Somit folgt}
  &=\sqrt{2}\,.
\end{align*}

\paragraph{B4A1.7}
$\mathbb{N}$-wertige Zufallsvariable $X$ zu sich selbst unabhängig gilt genau dann, wenn $X$ fast sicher konstant ist.
\emph{Siehe handschriftliches Blatt.}
\paragraph{B4A1.8}
Es gilt $E[\mathbbm{1}_A\mathbbm{1}_B]=E[\mathbbm{1}_A]E[\mathbbm{1}_B]$ genau dann, wenn $A$ und $B$ unabhängig sind.
Ja.
Es gelte $E[\mathbbm{1}_A\mathbbm{1}_B]=E[\mathbbm{1}_A]E[\mathbbm{1}_B]$.
Dann gilt auch $P(A\cap B)=E[\mathbbm{1}_{A\cap B}]=E[\mathbbm{1}_A\mathbbm{1}_B]=E[\mathbbm{1}_A]E[\mathbbm{1}_B]=P(A)P(B)$.
Gelte andererseits, dass $A$ und $B$ unabhängig sind, dann folgt daraus, dass
$E[\mathbbm{1}_A\mathbbm{1}_B]=E[\mathbbm{1}_{A\cap B}]=P(A\cap B)=P(A)P(B)=E[\mathbbm{1}_A]E[\mathbbm{1}_B]$.
\paragraph{B4A1.9}
Für $X$ exponentialverteilt mit $\lambda=1$ gilt $E[X^4]\geq E[X]^4$.
Ja.
Das gilt mit konvexem $g(x)=x^4$ mithilfe der Jensen-Ungleichung aus Satz 8.
\paragraph{B4A1.10}
Gilt $\mu(A)=0$ genau dann, wenn $\nu(A)=0$, dann gibt es ein messbares $f$, sodass $\mu(A)=\int_A f(\omega)\nu(\mathrm{d}\omega)$?
Ja.
Denn wenn $\mu$ und $\nu$ dieselben Nullmengen besitzen gilt insbesondere $\mu\ll\nu$.
Da $\mu$ und $\nu$ als Wahrscheinlichkeitsmaße $\sigma$-endlich sind, können wir den Satz von Radon-Nikodym anwenden, nachdem $\mu$ eine Dichte bezüglich $\nu$ besitzt, also gerade eine Borel-messbare Abbildung, sodass $\mu(A)=\int_A f(\omega)\nu(\mathrm{d}\omega)$.
\paragraph{B4A1.11}
Auf $(\omega,\{\Omega,\emptyset\})$ gibt es keine Borel-messbare Abbildung?
Doch.
Sei $f=0$, dann für $A\in{\cal B}(\mathbb{R})$
\[
  f^{-1}(A)=
  \begin{cases}
    \emptyset,&0\notin A\,,\\
    \Omega,&0\in A\,.
  \end{cases}
\]
Somit gilt für alle $A\in{\cal B}(\mathbb{R})$, dass $f^{-1}(A)\in\{\emptyset,\Omega\}$ und folglich ist $f$ Borel-messbar.
\paragraph{B4A1.12}
Seien $X\sim\operatorname{Exp}(6)$ und $Y\sim\operatorname{Exp}\bigl(\frac{1}{3}\bigr)$, dann gilt $E[XY]\leq1$, wobei für $Z\sim\operatorname{Exp}(\lambda)$ gilt $E[Z]=\frac{1}{\lambda}$ und $E[Z^2]=\frac{2}{\lambda^2}$?
Ja.
Wie bei Aufgabenteil 6 gilt mit der Cauchy-Schwarz-Ungleichung
\begin{align*}
  E[XY]
  &\leq\sqrt{E[X^2]}\sqrt{E[Y^2]}\,.
    \intertext{Mit den Angaben zu den Parametern $\lambda=6$ beziehungsweise $\lambda=\frac{1}{3}$ der Verteilungen von $X$ beziehungsweise $Y$, sowie dem Hinweis auf dem Blatt ergibt sich}
  &=\sqrt{\frac{2}{6^2}\cdot\frac{2}{\left(\frac{1}{3}\right)^2}}=\frac{2}{\frac{6}{3}}=1\,.
\end{align*}
\paragraph{B4A1.13}
Ist $q\leq p$ und $X\in L^p(\Omega,{\cal F},P)$, so ist $X\in L^q(\Omega,{\cal F},P)$?
Ja.
Nach Satz 6.\emph{vi} gilt $\|X\|_q\leq\|X\|_p<\infty$, da nach Aufgabe $X\in L^p(\Omega,{\cal F},P)$.
Da in $L^q(\Omega,{\cal F},P)$ alle $P$-messbaren $\overline{\mathbb{R}}$-wertigen Funktionen mit endlicher $L^q$-Norm sind, ist $X\in{\cal L}^q(\Omega,{\cal F},P)$.
\newpage

\paragraph{B4A2}
Seien $(X_n)$ Zufallsvariablen sodass $X_1=0$ und $X_n=\sqrt{n}\mathbbm{1}_{(\frac{1}{n},\frac{2}{n})}$ auf $([0,1],{\cal B}([0,1]),\lambda|_{[0,1]})$.
\subparagraph{B4A2.1} $(X_n)$ konvergiert in Wahrscheinlichkeit.

\subparagraph{B4A2.2} $(X_n)$ konvergiert fast sicher.

\subparagraph{B4A2.3} $(X_n)$ konvergiert in $L_2$.

\subparagraph{B4A2.4} $(X_n)$ ist gleichgradig integrierbar.

\emph{Siehe zur Lösung der Aufgabe 2 das handschriftliche Blatt.}
\newpage

\paragraph{B4A3} Seien $(X_n)$ Zufallsvariablen, sodass $X_n(\omega)=\omega^{\frac{1}{n}}$ auf $([0,1],{\cal B}([0,1]),P)$, wobei $P\ll\lambda|_{[0,1]}$ mit Dichte $f(\omega)=\frac{1}{2}\omega^{-\frac{1}{2}}$.
\subparagraph{B4A2.1} $(X_n)$ konvergiert in Wahrscheinlichkeit.
Wir möchten entscheiden, ob $(X_n)$ in Wahrscheinlichkeit konvergiert.
Da die Folge $\omega^{\frac{1}{n}}$ für alle $\omega\in(0,1]$ gegen 1 konvergiert, vermuten wir, dass $X_n\xrightarrow{P}1$.
Um das zu prüfen, sei ein $\varepsilon>0$ vorgegeben.
Da für alle $n\in\mathbb{N}$ und alle $\omega\in[0,1]$ gilt, $X_n(\omega)\leq1$, können wir in der Definition der Konvergenz in Wahrscheinlichkeit die Betragsstriche weglassen.
Nach Markov-Ungleichung gilt für alle $n\in\mathbb{N}$
\begin{align*}
\varepsilon P(1-\omega^\frac{1}{n}\geq\varepsilon)
  &\leq E\bigl[1-\omega^\frac{1}{n}\bigr]\,.
    \intertext{Mit einsetzen der Dichte vom Aufgabenblatt folgt}
  &\int_{0}^1\bigl(1-\omega^\frac{1}{n}\bigr)\frac{1}{2}\omega^{-\frac{1}{2}}\mathrm{d}\omega\,.
   \intertext{Durch Ausmultiplizieren und Integrieren von $\frac{1}{2}\omega^{-\frac{1}{2}}$ erhalten wir}
  &=\sqrt{1}-\sqrt{0}+\int_0^1\frac{1}{2}\omega^{\frac{1}{n}-\frac{1}{2}}\mathrm{d}\omega\,.
    \intertext{Ausführen der Wurzel und Erneutes Integrieren liefert}
  &=1-\left.\frac{n}{n+2}\omega^\frac{n+2}{2n}\right|_0^1\,.
    \intertext{Indem wir die Grenzen einsetzen und beide Terme auf einen gemeinsamen Nenner bringen, erhalten wir}
  &=\frac{2}{n+2}\,.
\end{align*}
Da für alle $\varepsilon>0$ gilt $\lim_n\frac{1}{\varepsilon}\frac{2}{n+2}=0$ sehen wir, dass $(X_n)$ in Wahrscheinlichkeit konvergiert.
\subparagraph{B4A2.2} $(X_n)$ konvergiert fast sicher.
Wir möchten uns überlegen, ob $P\bigl(\lim\omega^{\frac{1}{n}}<1\bigr)=0$.
Das einzige Problem könnte in einer Umgebung um $\omega=0$ auftauchen, denn $0^\frac{1}{n}=0$ für alle $n\in\mathbb{N}$.
Da $\omega=0$ jedoch der einzige Punkt ist, sodass $\lim \omega^\frac{1}{n}<1$, ist $\{\lim \omega^\frac{1}{n}<1\}$ in der Tat eine $P$-Nullmenge.
Somit konvergiert $(X_n)$ fast sicher.

\subparagraph{B4A2.3} $(X_n)$ konvergiert aufgrund der Argumentation in Teilaufgabe 1 in $L^1$.
Es gilt $E[1-\omega^{\frac{1}{n}}]=\frac{2}{n+2}$, was für $n\to\infty$ gegen 0 konvergiert.

\subparagraph{B4A2.4} $(X_n)$ ist gleichgradig integrierbar, da es in $L^1$ konvergiert.
\newpage

\bibliography{../../../books/wt}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% ispell-local-dictionary: "german"
%%% TeX-master: t
%%% End:
